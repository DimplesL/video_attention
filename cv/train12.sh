nohup th train.lua -input_h5 /data/coco/coco.h5 \
             -input_json /data/coco/coco_vocab.json \
             -gpu 3 \
             -batch_size 16 \
             -seq_length 51 \
             -model_type "lstm" \
             -wordvec_size 1024 \
             -rnn_size 2048 \
             -num_layers 2 \
             -learning_rate 0.001 \
             -checkpoint_every 250 \
             -checkpoint_name /data/checkpoints/16_1024_1000_2 \
             -lr_decay_every 1000 \
             -max_epochs 500 > train12.log &
